# Lab 2: CPU Integration - First Steps

## Part 2a: Chipyard Tour 

### Summary So Far

In Lab 1, you learned Chisel and (probably) blindly went through Chipyard setup. We talked a little bit about Chisel, VLSI flows, and Chipyard in lecture one, and then dug a bit deeper into SoC design and Rocket Chip in lecture two, particularly focusing on the SoC component hopefully most familiar to you from EECS151LA - the RISC-V core. You no doubt still have many questions - that's okay! Hopefully our meet-ups will ease you into this chaotic infrastructure smoothly, but please do let us know when you encounter bugs or confusion. Now, we would like to start the process of integrating your own core into the brand new SoC. 

### Chipyard & Rocket Chip Overview

So, we've asked you to setup Chipyard. What in the world did we make you clone?! In this lab, we will explore the [Chipyard](https://github.com/ucb-bar/chipyard) framework a bit deeper. As you read the documentation, you will see many diagrams, such as the one below, each of which seems to have more and more new components. Again, don't worry about trying to explore everything at once.

![](Lab_2_assets/chipyard-flow.png)

**To start - what is Chipyard?**

Chipyard is an integrated design, simulation, and implementation framework for open source hardware development developed here at UC Berkeley. It is open-sourced online and is based on the Chisel and FIRRTL hardware description libraries, as well as the Rocket Chip SoC generation ecosystem. It brings together much of the work on hardware design methodology from Berkeley over the last decade as well as useful tools into a single repository that guarantees version compatibility between the projects it submodules.

A designer can use Chipyard to build, test, and tapeout (manufacture) a RISC-V-based SoC. This includes RTL development integrated with Rocket Chip, cloud FPGA-accelerated simulation with FireSim, and physical design with the Hammer framework.

(As you learned in Lab 1) Chisel is the primary hardware description language used at Berkeley. It is a domain-specific language built on top of Scala. Thus, it provides designers with the power of a modern programming language to write complex, parameterizable circuit generators that can be compiled into synthesizable Verilog. 

Throughout the rest of the course, we will be developing our SoC using Chipyard as the base framework. 

There is a lot in Chipyard so we will only be able to explore a part of it in this lab, but hopefully you will get a brief sense of its capabilities. 

Note that while we talked about the *Rocket Chip* ecosystem in lecture, *Chipyard* (the name) is often used near interchangeably, and we will say *Chipyard* from now on. 

### Chipyard Repo Tour

(_Credit: Jerry Zhao_)

> <b>You will mostly be working out of the `generators/` (for designs), `sims/vcs/` (for simulations)* and `vlsi/` (for physical design) directories.</b> 
However, we will still give a general repo tour to get you familiar with Chipyard as a whole.

###### *VCS is a proprietary simulation tool provided by Synopsys while Verilator is an open-source tool. There are some subtle differences form the user perspective, but VCS is usually faster so we'll be using that throughout the course. Everthing done with VCS can easily also be done in Verilator (the subdirectory structure is the same as well). If this changes, we will let you know.

```
 $chipyard/
  generators/ <------- library of Chisel generators
    chipyard/
    sha3/
  sims/ <------------- utilities for simulating SoCs
    vcs/
    verilator/
    firesim/
  fpga/
  software/
  vlsi/ <------------- HAMMER VLSI Flow
  toolchains/ <------- RISC-V Toolchain
```

You may have noticed while initializing your Chipyard repo that there are many submodules. Chipyard is built to allow the designer to generate complex configurations from different projects including the in-order Rocket Chip core, the out-of-order BOOM core, the systolic array Gemmini, and many other components needed to build a chip.
Thankfully, Chipyard has some great documentation, which can be found 
[here](https://chipyard.readthedocs.io/en/latest/). 

You can find most of these in the `$chipyard/generators/` directory.
All of these modules are built as generators (a core driving point of using Chisel), which means that each piece is parameterized and can be fit together with some of the functionality in Rocket Chip (check out the [TileLink and Diplomacy references](https://chipyard.readthedocs.io/en/stable/TileLink-Diplomacy-Reference/index.html) in the Chipyard documentation).

### SoC Architecture 

We will talk about some of these in more depth in later lectures, but here's a preview in written format (again, credit to Jerry Zhao). Apologies in advance if the formatting breaks a bit - we will fix in the future. You *don't* need to understand each of the below, unless you want to.

<table border-"0">
  <tr>
    <td><img src="Lab_2_assets/rtl_gen_layer.png" width=700 /></td>
    <td><img src="Lab_2_assets/chipyard.jpg" /></td>
  </tr>
</table>
 
          

<table border="0">
 <tr>
    <td><img style="float: left;" src="Lab_2_assets/tile.jpg" width="200"></td>
    <td>
      <h2>Tiles</h2>
      <ul>
        <li> A tile is the basic unit of replication of a core and its associated hardware
        <li> Each tile contains a RISC-V core and can contain additional hardware such as private caches, page table walker, TileBus (specified using configs)
        <li> Several varieties of cores (<a href="https://chipyard.readthedocs.io/en/stable/Generators/Rocket.html">Rocket</a>, <a href="https://chipyard.readthedocs.io/en/stable/Generators/BOOM.html">BOOM</a>, <a href="https://chipyard.readthedocs.io/en/stable/Generators/Sodor.html">Sodor</a>, <a href="https://chipyard.readthedocs.io/en/stable/Generators/CVA6.html">CVA-6 (Ariane)</a>, <a href="https://chipyard.readthedocs.io/en/stable/Generators/Ibex.html">Ibex</a> supported)
        <li> Interface supports integrating your own RISC-V core implementation
      </ul>
    </td>
  </tr>

  <tr>
    <td><img style="float: left;" src="Lab_2_assets/rocc.jpg" width="200"></td>
    <td>
      <h2>RoCC Accelerators</h2>
      <ul>
        <li> Tightly-coupled accelerator interface
        <li> Attach custom accelerators to Rocket or BOOM cores
        <li> Example: <a href="https://github.com/ucb-bar/gemmini/tree/c47cb7f3eb5c18390f176f3a53c43c8546d487d2">GEMMINI accelerator</a> 
      </ul>
    </td>
  </tr>


  <tr>
    <td><img style="float: left;" src="Lab_2_assets/mmio.jpg" width="200"></td>
    <td>
      <h2>MMIO Accelerators</h2>
      <ul>
        <li> Controlled by memory-mapped IO registers
        <li> Support DMA to memory system
        <li> Examples: <a href="http://nvdla.org/">Nvidia NVDLA accelerator</a> & <a href="https://chipyard.readthedocs.io/en/stable/Generators/fft.html">FFT accelerator generator </a>
      </ul>
    </td>
  </tr>

  <tr>    
    <td>
      <table border="0">
        <tr>
        </tr>
        <tr>
          <td><img style="float: left;" src="Lab_2_assets/tilelink.jpg" width="200"></td>
        </tr>
        <tr>
          <td><img style="float: left;" src="Lab_2_assets/noc.jpg" width="200"></td>
        </tr>
      </table>
    </td>
    <td>
      <table border="0">
        <tr>
          <td><h2>Chip Interconnect</h2></td>
        </tr>
        <tr>
          <td>
            <h3>TileLink Standard</h3>
            <ul>
              <li> TileLink is an open-source chip-scale interconnect standard (i.e., a protocol defining the communication interface between different modules on a chip)
              <li> Comparable to industry-standard protocols such as AXI/ACE
              <li> Supports multi-core, accelerators, peripherals, DMA, etc.
            </ul>
            <h3>Interconnect IP in Chipyard</h3>
            <ul>
              <li> Library of TileLink RTL generators provided in RocketChip
              <li> RTL generators for crossbar-based buses
              <li> Width-adapters, clock-crossings, etc.
              <li> Adapters to AXI4, APB
            </ul>
          </td>
        </tr>
        <tr>
          <td>
            <h3>Constellation</h3>
            <ul>
              <li> A parameterized Chisel generator for SoC interconnects
              <li> Protocol-independent transport layer
              <li> Supports TileLink, AXI-4
              <li> Highly parameterized
              <li> Deadlock-freedom
              <li> Virtual-channel wormhole-routing
            </ul>
          </td>
        </tr>
      </table>
    </td>
  </tr>

  <tr>
    <tr>
      <td><img style="float: left;" src="Lab_2_assets/shared_mem.jpg" width="200"></td>
      <td>
        <h2>Shared Memory</h2>
        <ul>
          <li> Open-source L2 cache that communicates over TileLink (developed by SiFive, iykyk)
          <li> Directory-based coherence with MOESI-like protocol
          <li> Configurable capacity/banking
          <li> Support broadcast-based coherence in no-L2 systems
          <li> Support incoherent memory systems
        </ul>
        <h2>DRAM</h2>
        <ul>
          <li> AXI-4 DRAM interface to external memory controller
          <li> Interfaces to DRAM simulators such as DRAMSim/FASED
        </ul>
      </td>
    </tr>
  </tr>

  <tr>
    <td><img style="float: left;" src="Lab_2_assets/peripherals.jpg" width="200"></td>
    <td>
      <h2>Peripherals and IO</h2>
      <ul>
        <li>  <a href="https://docs.google.com/document/d/13rCqMM0qARjcLTrkwqlTzNClU-cxjUnZE0jHnIoe4UU/edit?usp=sharing">Chipyard Peripheral User Manual </a>  put together by Yufeng Chi who took the Sp22 iteration of the 4-unit Tapeout class. This document is a living document, so feel to add comments on sections that you don't understand/woud like to see added. 
        <li> Open-source RocketChip + SiFive blocks:
        <ul>
          <li> Interrupt controllers
          <li> JTAG, Debug module, BootROM
          <li> UART, GPIOs, SPI, I2C, PWM, etc.
        </ul>
        <li> TestChipIP: useful IP for test chips
        <ul>
          <li> Clock-management devices
          <li> SerDes
          <li> Scratchpads
        </ul>
       <li>Documentations of the peripheral devices can be found <a href="https://drive.google.com/file/d/1aDYtmHgG30Gy591TaNlya2rcc54nn9gZ/view?usp=sharing">here</a></li>
      </ul>
    </td>
  </tr>

</table>

<table border-"0">
  <tr>
    <td><img src="Lab_2_assets/config_gen_layer.png" width=1000 /></td>
    <td><img alt="How Configs Work" src="Lab_2_assets/02_chipyard_basics.gif" width=660></td>
  </tr>
</table>

A sort of summary:

- Configs: Describe parameterization of a multi-generator SoC.

- Generators: Flexible, reusable library of open-source Chisel generators (and Verilog too).

- IOBinders/HarnessBinders: Enable configuring IO strategy and Harness features.

- FIRRTL Passes: Structured mechanism for supporting multiple flows.

- Target flows: Different use-cases for different types of users.

### An Actual Deliverable?! Config Exercise

A good way to prevent information overload is to map these ideas to the actual repository. This small config exercise will help!

Configs describe what goes into our final system and what parameters our designs are elaborated with. You can find the configs in `$chipyard/generators/chipyard/src/main/scala/config`.

Look at the configs located in `$chipyard/generators/chipyard/src/main/scala/config/RocketConfigs.scala`, specifically `RocketConfig`.

```
class RocketConfig extends Config(
  new freechips.rocketchip.subsystem.WithNBigCores(1) ++         // single rocket-core
  new chipyard.config.AbstractConfig)                            // builds one on top of another, so the single rocket-core is built on top of the AbstractConfig
```

<table border-"0">
  <tr>
    <td>
    RocketConfig is part of the "Digital System configuration" depicted below. It is built on top of the AbstractConfig which contains the config fragments (each line like <code>freechips.rocketchip.subsystem.WithNBigCores(1)</code> that adds something to the overall system is called a config fragment) for IO Binders and Harness Binders (depicted below).
    </td>
    <td><img src="Lab_2_assets/io_high_level.jpg" width = 1700/></td>
  </tr>
</table>


<table border-"0">
  <tr>
    <td><img src="Lab_2_assets/io_harness.jpg" /></td>
    <td><img src="Lab_2_assets/io_harness_map.jpg"/></td>
  </tr>
</table>

Inspect `TinyRocketConfig` & answer the questions on Gradescope. You should be able to find the answers or clues to the answers by `grepping` in `$chipyard/generators/chipyard/src/main/scala/` or `$chipyard/generators/rocket-chip/src/main/scala/`.

**(Lab Part 2a Deliverable) Complete the assignment on Gradescope.**

## Part 2b: Starting the Black Box

### Import Your CPU

Unlike the `RocketConfig` example, we don't care as much about generating a Rocket Core - we want to integrate your own! We suggest doing this by creating a brand new generator which will "generate" your core on demand. But first, we need to find and condense your EECS151LA RTL.

**Step 1: Go to `$chipyard/generators`**

You will see a whole bunch of submodules, each pointing an open-source generator project. 

**Step 2: Create your project folder** 

To simplify things, we will not turn your core into a submodule. Instead, create this folder:  

`mkdir -p generators/shadow-council/src/main/resources/vsrc/cores`

The filepath *has* to match, else flows may break person to person. 

**Step 3: Import your core**

Find your EECS151 CPU repository. Clone it to the instructional server. Essentially, copy over the whole folder to the this new generator path. For example, I may now have a filepath:

``generators/shadow-council/src/main/resources/vsrc/cores/fa24-name-of-my-core/`

With the directory structure:

```
 $chipyard/
  generators/ <------- library of Chisel generators
    shadow-council/src/main/resources/vsrc/cores/fa24-name-of-my-core/
      src/
      tests/
      Makefile
      README.md
      *.yml files
  ...
```

The structure will differ depending on what semester you took EECS151 in.

Again, while in a perfect world you would want to submodule, don't do that here - we/you will need to modify your core later and if you submodule, we might have access issues to your repo. 

**Step 4: Submit your core filepath on Gradescope.**

### Condense Your Verilog 

To our knowledge so far, black boxing in Chisel only works for one Verilog file at a time. However, independently integrating every piece of your CPU would be painful.
So instead, we (specifically: elam) wrote a Makefile that will turn your CPU into one very, very long Verilog file. It is very far from perfect but should get the job done.

**Step 1: Grab the Makefile from `Lab_2_Materials` and place it in your /cores/ directory.**

Specifically, `generators/shadow-council/src/main/resources/vsrc/cores/`.

**Step 2: Change `proj_name` inside the Makefile**

To your project folder name. In the above example, I would write:

``proj_name = fa24-name-of-my-core``

**Optional: Look through the Makefile! Improve it?**

If you don't have Make experience, this is your chance to see what's behind the "magic" in your regular classes! That is... there's no magic at all, just a bunch of very hack-y scripts. You will see more impressive Makefiles throughout Chipyard. 

There's a bunch of "TO DOs" in it. If you end up getting bored and want a challenge sometime, you can try to make improvements to this part of the flow - but we won't make (pun intended) you suffer through that!

**Step 3: Run the Makefile**

In the directory you added the Makefile to, run `make`. 

**Step 4: Submit the path to your generated Verilog on Gradescope**

You can check the Makefile to figure out where the combined verilog file gets placed if you can't find it. Or you can ask someone, but where's the fun in that?

Congratz! Your core is now one step closer to integration. But the resulting file is still Verilog. How do we turn it into Scala?

### Chisel Black Box Integration (First Steps)

For this part of the lab, we will leave things a little vague. Try to complete these tasks! Do not despair if things don't work - we want to see where people get stuck.

**Step 1: Create a `scala` directory**

You already have `generators/shadow-council/src/main/resources/vsrc/cores/`, where `vsrc` refers to Verilog source. Now we want a place for our Scala. Create this directory:

`generators/shadow-council/src/main/scala` 

(There is no law saying to follow this structure, we're just trying to be consistent for the sake of flows.)

**Step 2: Create a `scala` file**

You will need a Scala file for your black box. So make a file! It can have any name, such as:

`generators/shadow-council/src/main/scala/<yourname>CoreBlackBox.scala`

**Step 3: Try writing a Scala black box!**

This is where things get vague and we're only looking for effort. Show us your interpretation!

**Hints**: 

We keep talking about this idea of a `Black Box`. We brought up Chipyard documentation in lecture a little bit, but didn't go into details.

Thankfully, Chipyard has a whole page dedicated to **6.4. Adding a custom core**:

- https://chipyard.readthedocs.io/en/stable/Customization/Custom-Core.html

In our case, **6.4.1. Wrap Verilog Module with Blackbox (Optionall)** is *not* optional. Take a look at that part of the documentation:

- https://chipyard.readthedocs.io/en/stable/Customization/Incorporating-Verilog-Blocks.html#incorporating-verilog-blocks

- Notice that we already guided you through `6.11.1. Adding a Verilog Blackbox Resource File` - feel free to read that segment, although it references quite a few things that may not make sense yet.

- Read through **6.11.2. Defining a Chisel BlackBox** onwards - this is what we want you to do! 

Please keep your file(s) in `generators/shadow-council/src/main/scala/`. If you decide to go further and experiment with more integration, we recommend you make a separate branch so that you can return to this first part if things don't work out.

You can also look at examples of how your own Chisel modules or verilog black-box modules can be integrated into a Rocket Chip-based SoC in `$chipyard/generators/chipyard/src/main/scala/example`.

**Step 4: Submit the absolute path, in addition to the eda machine, of your core blackbox scala file and answer any questions there may be.**

# Credits

(_This segment partially borrows from the Spring 2023 Tapeout Lab 2, particularly the writings of Jerry Zhao._)
